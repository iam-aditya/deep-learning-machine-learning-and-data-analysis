{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text generation model.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "c08i4C4-4qZr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yl7cCA0N46em",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "63811dcc-b949-40e5-c090-b0a1c2b80889"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5861a000 @  0x7f6c529882a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PNwNUX8W5MUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6070bd8c-41bf-4b6e-af5d-1138e75296dd"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "viLet-sz5QkN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        \n",
        "        # This is very english language specific\n",
        "        # We will ingest only these characters:\n",
        "        self.whitelist = [chr(i) for i in range(32, 127)]\n",
        "        \n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r',  encoding=\"utf8\") as f:\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                line = ''.join([c for c in line if c in self.whitelist])\n",
        "                words = line.split() + ['<eos>']\n",
        "                tokens += len(words)\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r',  encoding=\"utf8\") as f:\n",
        "            ids = torch.LongTensor(tokens)\n",
        "            #print((ids.size()))\n",
        "            token = 0\n",
        "            for line in f:\n",
        "                line = ''.join([c for c in line if c in self.whitelist])\n",
        "                words = line.split() + ['<eos>']\n",
        "                #print(words)\n",
        "                for word in words:\n",
        "                    ids[token] = self.dictionary.word2idx[word]\n",
        "                    token += 1\n",
        "\n",
        "        return ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70KtFvCy5jD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = Corpus('/content/gdrive/My Drive/iris/shakespear/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6WIBZNSy5jwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d297baa-4aee-4e04-9624-411d5ba98de9"
      },
      "cell_type": "code",
      "source": [
        "#not important\n",
        "path='/content/gdrive/My Drive/iris/shakespear/'\n",
        "path=os.path.join(path, 'valid.txt')#concatanates \n",
        "print(path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/iris/shakespear/valid.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KqPUAdnj6YCe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "5cadc3ad-6485-4aa8-cadd-37104a5f5d76"
      },
      "cell_type": "code",
      "source": [
        "#not important\n",
        "whitelist = [chr(i) for i in range(32, 127)]\n",
        "print(whitelist)\n",
        "\n",
        "print(type(whitelist))\n",
        "with open(path, 'r',  encoding=\"utf8\") as f:\n",
        "            tokens = 0\n",
        "            for line in f:\n",
        "                #print(line)\n",
        "                line = \"\".join([c for c in line if c in whitelist])\n",
        "                #print(line)\n",
        "                words = line.split() + ['<eos>']\n",
        "                tokens += len(words)\n",
        "              \n",
        "with open(path, 'r',  encoding=\"utf8\") as f:\n",
        "            ids = torch.LongTensor(tokens)\n",
        "            print(type(ids))\n",
        "            token = 0\n",
        "            for line in f:\n",
        "                line = ''.join([c for c in line if c in whitelist])\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    ids[token] = dictionary.word2idx[word]\n",
        "                    token += 1              \n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
            "<class 'list'>\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-19e61e4aa56e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhitelist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-19e61e4aa56e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhitelist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                 \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'<eos>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "njQ7cHRT7zB4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers, dropout=0.5):\n",
        "        \n",
        "        super(RNNModel, self).__init__()\n",
        "        \n",
        "        self.encoder = nn.Embedding(vocab_size, embed_size)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.drop2 = nn.Dropout(dropout)\n",
        "        self.rnn = nn.GRU(embed_size, hidden_size, num_layers, dropout=dropout)\n",
        "        self.decoder = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.fill_(0)\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop1(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop2(output)\n",
        "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
        "        return decoded.view(output.size(0), output.size(1), decoded.size(1)), hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        return Variable(weight.new(self.num_layers, batch_size, self.hidden_size).zero_())\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnbGlcalaD4Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def batchify(data, batch_size):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // batch_size\n",
        "    print(data.size(0),batch_size, nbatch)\n",
        "    print(\"initialy \",data)\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * batch_size)\n",
        "    print(\".narraow() \",data)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(batch_size, -1)\n",
        "    print(data)\n",
        "    data=data.t()\n",
        "    print(\"applied a transppose \",data)\n",
        "    data=data.contiguous()#important just use it\n",
        "    print(data)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d-Qayix5aGK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "da855f10-3811-461d-96d9-9d934ff91c1f"
      },
      "cell_type": "code",
      "source": [
        "dummy_data = \"Once upon a time there was a good king and  a queen\"\n",
        "dummy_data_idx = [corpus.dictionary.word2idx[w] for w in dummy_data.split()]\n",
        "print(dummy_data_idx)\n",
        "dummy_tensor = torch.LongTensor(dummy_data_idx) \n",
        "op = batchify(dummy_tensor, 2)\n",
        "for row in op:\n",
        "    print(row[0],row[1])\n",
        "    print(\"%10s %10s\" %  (corpus.dictionary.idx2word[row[0]], corpus.dictionary.idx2word[row[1]]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9917, 845, 46, 23, 994, 1538, 46, 1171, 2463, 90, 46, 5574]\n",
            "12 2 6\n",
            "initialy  tensor([9917,  845,   46,   23,  994, 1538,   46, 1171, 2463,   90,   46, 5574])\n",
            ".narraow()  tensor([9917,  845,   46,   23,  994, 1538,   46, 1171, 2463,   90,   46, 5574])\n",
            "tensor([[9917,  845,   46,   23,  994, 1538],\n",
            "        [  46, 1171, 2463,   90,   46, 5574]])\n",
            "applied a transppose  tensor([[9917,   46],\n",
            "        [ 845, 1171],\n",
            "        [  46, 2463],\n",
            "        [  23,   90],\n",
            "        [ 994,   46],\n",
            "        [1538, 5574]])\n",
            "tensor([[9917,   46],\n",
            "        [ 845, 1171],\n",
            "        [  46, 2463],\n",
            "        [  23,   90],\n",
            "        [ 994,   46],\n",
            "        [1538, 5574]])\n",
            "tensor(9917) tensor(46)\n",
            "      Once          a\n",
            "tensor(845) tensor(1171)\n",
            "      upon       good\n",
            "tensor(46) tensor(2463)\n",
            "         a       king\n",
            "tensor(23) tensor(90)\n",
            "      time        and\n",
            "tensor(994) tensor(46)\n",
            "     there          a\n",
            "tensor(1538) tensor(5574)\n",
            "       was      queen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jWmVRlR1aKPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs_train = 20       # batch size for training set\n",
        "bs_valid = 10       # batch size for validation set\n",
        "bptt_size = 35      # number of times to unroll the graph for back propagation through time\n",
        "clip = 0.25         # gradient clipping to check exploding gradient\n",
        "\n",
        "embed_size = 200    # size of the embedding vector\n",
        "hidden_size = 200   # size of the hidden state in the RNN \n",
        "num_layers = 2      # number of RNN layres to use\n",
        "dropout_pct = 0.5   # %age of neurons to drop out for regularization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHZD5WzIaRmA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "fdd62654-7dec-47b0-cc40-324a13aceb9c"
      },
      "cell_type": "code",
      "source": [
        "train_data = batchify(corpus.train, bs_train)\n",
        "val_data = batchify(corpus.valid, bs_valid)\n",
        "vocab_size = len(corpus.dictionary)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1039900 20 51995\n",
            "initialy  tensor([    0,     1,     2,  ...,     0, 70634,     0])\n",
            ".narraow()  tensor([    0,     1,     2,  ...,     0, 70634,     0])\n",
            "tensor([[    0,     1,     2,  ...,    19,  9604,     0],\n",
            "        [  254,  9605,  9606,  ..., 15550,  1097,    33],\n",
            "        [ 5415,   202,   183,  ...,  4083,   496, 20229],\n",
            "        ...,\n",
            "        [  690,   590,   756,  ...,  1893,   119, 29855],\n",
            "        [    0,   136,   856,  ...,   756,   705, 11792],\n",
            "        [ 1045,    33,   111,  ...,     0, 70634,     0]])\n",
            "applied a transppose  tensor([[    0,   254,  5415,  ...,   690,     0,  1045],\n",
            "        [    1,  9605,   202,  ...,   590,   136,    33],\n",
            "        [    2,  9606,   183,  ...,   756,   856,   111],\n",
            "        ...,\n",
            "        [   19, 15550,  4083,  ...,  1893,   756,     0],\n",
            "        [ 9604,  1097,   496,  ...,   119,   705, 70634],\n",
            "        [    0,    33, 20229,  ..., 29855, 11792,     0]])\n",
            "tensor([[    0,   254,  5415,  ...,   690,     0,  1045],\n",
            "        [    1,  9605,   202,  ...,   590,   136,    33],\n",
            "        [    2,  9606,   183,  ...,   756,   856,   111],\n",
            "        ...,\n",
            "        [   19, 15550,  4083,  ...,  1893,   756,     0],\n",
            "        [ 9604,  1097,   496,  ...,   119,   705, 70634],\n",
            "        [    0,    33, 20229,  ..., 29855, 11792,     0]])\n",
            "63420 10 6342\n",
            "initialy  tensor([    1, 70635, 70636,  ...,     0,     0,     0])\n",
            ".narraow()  tensor([    1, 70635, 70636,  ...,     0,     0,     0])\n",
            "tensor([[    1, 70635, 70636,  ...,  3790,   341,   705],\n",
            "        [ 3126,  4756,  2705,  ..., 71190,     0,   590],\n",
            "        [  202,   111, 71191,  ...,   190,    46, 45716],\n",
            "        ...,\n",
            "        [  214,   374, 16827,  ..., 21270,   108,   214],\n",
            "        [73149,  1156, 73150,  ...,  2062,   183,    33],\n",
            "        [ 1184,  4215,     0,  ...,     0,     0,     0]])\n",
            "applied a transppose  tensor([[    1,  3126,   202,  ...,   214, 73149,  1184],\n",
            "        [70635,  4756,   111,  ...,   374,  1156,  4215],\n",
            "        [70636,  2705, 71191,  ..., 16827, 73150,     0],\n",
            "        ...,\n",
            "        [ 3790, 71190,   190,  ..., 21270,  2062,     0],\n",
            "        [  341,     0,    46,  ...,   108,   183,     0],\n",
            "        [  705,   590, 45716,  ...,   214,    33,     0]])\n",
            "tensor([[    1,  3126,   202,  ...,   214, 73149,  1184],\n",
            "        [70635,  4756,   111,  ...,   374,  1156,  4215],\n",
            "        [70636,  2705, 71191,  ..., 16827, 73150,     0],\n",
            "        ...,\n",
            "        [ 3790, 71190,   190,  ..., 21270,  2062,     0],\n",
            "        [  341,     0,    46,  ...,   108,   183,     0],\n",
            "        [  705,   590, 45716,  ...,   214,    33,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GF_MRxWUaScA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = RNNModel(vocab_size, embed_size, hidden_size, num_layers, dropout_pct)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "def get_batch(source, i, evaluation=False):\n",
        "    seq_len = min(bptt_size, len(source) - 1 - i)\n",
        "    data = Variable(source[i:i+seq_len], volatile=evaluation)\n",
        "    data.contiguous()\n",
        "    target = Variable(source[i+1:i+1+seq_len].view(-1))\n",
        "    #cuda \n",
        "    return data, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e01c975daoF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data, target = get_batch(train_data, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y6KT9gXGasaN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(data_source, lr):\n",
        "    \n",
        "    \n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    hidden = model.init_hidden(bs_train)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    for batch, i in enumerate(range(0, data_source.size(0) - 1, bptt_size)):\n",
        "        \n",
        "        data, targets = get_batch(data_source, i)\n",
        "\n",
        "        \n",
        "        hidden = Variable(hidden.data)\n",
        "        \n",
        "        #if cuda.is_available():\n",
        "        #    hidden = hidden.cuda()\n",
        "        \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, hidden = model(data, hidden)\n",
        "        loss = criterion(output.view(-1, vocab_size), targets)\n",
        "        loss.backward()\n",
        "\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        total_loss += len(data) * loss.data\n",
        "        \n",
        "    return total_loss[0] / len(data_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lw3zimaua080",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    hidden = model.init_hidden(bs_valid)\n",
        "    \n",
        "    for i in range(0, data_source.size(0) - 1, bptt_size):\n",
        "        data, targets = get_batch(data_source, i, evaluation=True)\n",
        "        \n",
        "        #if cuda.is_available():\n",
        "        #   hidden = hidden.cuda()\n",
        "            \n",
        "        output, hidden = model(data, hidden)\n",
        "        output_flat = output.view(-1, vocab_size)\n",
        "        \n",
        "        total_loss += len(data) * criterion(output_flat, targets).data\n",
        "        hidden = Variable(hidden.data)\n",
        "        \n",
        "    return total_loss[0] / len(data_source)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybpyZds0a2Mx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_val_loss = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jjfPVWnwa7WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def run(epochs, lr):\n",
        "    global best_val_loss\n",
        "    \n",
        "    for epoch in range(0, epochs):\n",
        "        train_loss = train(train_data, lr)\n",
        "        val_loss = evaluate(val_data)\n",
        "        print(\"Train Loss: \", train_loss, \"Valid Loss: \", val_loss)\n",
        "\n",
        "        if not best_val_loss or val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), \"./4.model.pth\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lSbrGpILhuJC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run(5, 0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvae7lKxhv2x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run(5, 0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yESFFxq0h2iE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 200\n",
        "temperature = 1\n",
        "model = RNNModel(vocab_size, embed_size, hidden_size, num_layers, dropout_pct)\n",
        "model.load_state_dict(torch.load(\"./4.model.pth\"))\n",
        "\n",
        "#if cuda.is_available():\n",
        "#    model.cuda()\n",
        "    \n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6eJXfoQbUWc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temperature = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yDtjK0RYbZbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden = model.init_hidden(1)\n",
        "idx = corpus.dictionary.word2idx['I']\n",
        "input = Variable(torch.LongTensor([[idx]]).long(), volatile=True)\n",
        "\n",
        "if cuda.is_available():\n",
        "    input.data = input.data.cuda()\n",
        "\n",
        "print(corpus.dictionary.idx2word[idx], '', end='')\n",
        "\n",
        "for i in range(num_words):\n",
        "    output, hidden = model(input, hidden)\n",
        "    word_weights = output.squeeze().data.div(temperature).exp().cpu()\n",
        "    word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "    input.data.fill_(word_idx)\n",
        "    word = corpus.dictionary.idx2word[word_idx]\n",
        "\n",
        "    if word == '<eos>':\n",
        "        print('')\n",
        "    else:\n",
        "        print(word + ' ', end='')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}